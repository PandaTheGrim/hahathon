{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Анализ работы модели предсказания качества воздуха\n",
    "\n",
    "В работе используются:\n",
    "- модель с [Kaggle](https://www.kaggle.com/code/hamedetezadi/air-quality-prediction), в формате [ноутбука](https://colab.research.google.com/drive/14Tlqrmg76i7S33Gc5P5iFvjh7Ml2dXxB?usp=sharing)\n",
    "- датасет  «СОСТОЯНИЕ ЗАГРЯЗНЕНИЯ АТМОСФЕРЫ В\n",
    " ГОРОДАХ РОССИИ C 2007 ГОДА» - приложено в файлах ноута\n"
   ],
   "metadata": {
    "id": "1j1HOKNPqxKi"
   }
  },
  {
   "cell_type": "markdown",
   "source": "# Скачивание датасета",
   "metadata": {
    "id": "q1GYOSPSqW_Z"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import kagglehub\n",
    "\n",
    "dataset_name = \"shrutibhargava94/india-air-quality-data\"\n",
    "dataset_files_path = kagglehub.dataset_download(dataset_name)\n",
    "\n",
    "print(\"Path to dataset files:\", dataset_files_path)\n",
    "\n",
    "# перекладываем в проект то, что скачали в нормальной кодировке (data.csv)\n",
    "for filename in os.listdir(dataset_files_path):\n",
    "    source_file = os.path.join(dataset_files_path, filename)\n",
    "    if os.path.isfile(source_file):\n",
    "        destination_file = os.path.join(os.getcwd(), filename)\n",
    "        with open(source_file, 'rb') as src:\n",
    "            content = src.read()\n",
    "            decoded_content = content.decode('utf-8', errors='ignore')\n",
    "\n",
    "        with open(destination_file, 'w') as dst:\n",
    "            dst.write(decoded_content)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R3CsHZMMuNiS",
    "outputId": "3decd9ef-a388-49cb-f7f1-57283812464f",
    "ExecuteTime": {
     "end_time": "2025-01-31T16:30:36.908134Z",
     "start_time": "2025-01-31T16:30:35.859299Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.6)\n",
      "Path to dataset files: C:\\Users\\Ingvar\\.cache\\kagglehub\\datasets\\shrutibhargava94\\india-air-quality-data\\versions\\1\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Запускаем модель"
   ],
   "metadata": {
    "id": "M6ySxIkAskwu"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# Загрузка обученной модели\n",
    "model_path = 'Air_Quality_Prediction.joblib'  # Укажите путь к вашей модели\n",
    "try:\n",
    "    model = joblib.load(model_path)\n",
    "    print(\"Модель успешно загружена.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Ошибка: модель не найдена по пути {model_path}\")\n",
    "    model = None\n",
    "\n",
    "# Применение модели для прогнозов (если модель загружена)\n",
    "if model:\n",
    "    try:\n",
    "        # TODO то, что выкачивается с каггла (india-air-quality-data) модель не ест\n",
    "        data = pd.read_csv(\"data.csv\")\n",
    "        predictions = model.predict(data)\n",
    "        data['Predictions'] = predictions\n",
    "        print(\"Прогнозы успешно выполнены.\")\n",
    "\n",
    "        # Сохранение данных с прогнозами\n",
    "        predictions_file_path = 'predictions_air_quality.csv'\n",
    "        data.to_csv(predictions_file_path, index=False)\n",
    "        print(f\"Данные с прогнозами сохранены в файл {predictions_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при выполнении прогнозов: {e}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vk3_Syg1sihi",
    "outputId": "fa6ee615-4113-447d-c308-d1fc3c5ae632",
    "ExecuteTime": {
     "end_time": "2025-01-31T16:37:48.503485Z",
     "start_time": "2025-01-31T16:37:47.728954Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ingvar\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator LinearRegression from version 1.6.1 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель успешно загружена.\n",
      "Ошибка при выполнении прогнозов: The feature names should match those that were passed during fit.\n",
      "Feature names unseen at fit time:\n",
      "- agency\n",
      "- date\n",
      "- location\n",
      "- location_monitoring_station\n",
      "- no2\n",
      "- ...\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- Noi\n",
      "- Rpi\n",
      "- SOi\n",
      "- SPMi\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ingvar\\AppData\\Local\\Temp\\ipykernel_17360\\4121270145.py:17: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"data.csv\")\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "source": [
    "expected_features = model.feature_names_in_\n",
    "print(\"Ожидаемые моделью признаки:\", expected_features)\n",
    "print(\"Текущие признаки данных:\", data.columns.tolist())\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "skzGj4MUwdj8",
    "outputId": "b8c03839-290d-48d7-88b4-dcfb496f639f",
    "ExecuteTime": {
     "end_time": "2025-01-31T16:34:25.702812Z",
     "start_time": "2025-01-31T16:34:25.697855Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ожидаемые моделью признаки: ['SOi' 'Noi' 'Rpi' 'SPMi']\n",
      "Текущие признаки данных: ['stn_code', 'sampling_date', 'state', 'location', 'agency', 'type', 'so2', 'no2', 'rspm', 'spm', 'location_monitoring_station', 'pm2_5', 'date']\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import re\n",
    "\n",
    "# Загрузка данных\n",
    "file_path = 'data_air_cities_100_v20231129.csv'\n",
    "dataset_files_path = pd.read_csv(file_path, sep=';', engine='python')\n",
    "\n",
    "# Очистка числовых данных от текста\n",
    "def extract_first_number(value):\n",
    "    if isinstance(value, str):\n",
    "        match = re.search(r'\\d+(\\.\\d+)?', value)\n",
    "        return float(match.group()) if match else np.nan\n",
    "    return value\n",
    "\n",
    "numeric_columns = ['air_solid_emissions', 'air_so_emissions', 'air_no_emissions', 'air_co_emissions', 'air_population', 'air_repeatability']\n",
    "for col in numeric_columns:\n",
    "    dataset_files_path[col] = dataset_files_path[col].apply(extract_first_number)\n",
    "\n",
    "# Обработка пропущенных значений\n",
    "categorical_columns = ['region', 'city', 'air_general_level', 'air_standard_index']\n",
    "\n",
    "# Заполнение числовых данных средним значением\n",
    "dataset_files_path[numeric_columns] = dataset_files_path[numeric_columns].fillna(dataset_files_path[numeric_columns].mean())\n",
    "\n",
    "# Заполнение категориальных данных модой\n",
    "for col in categorical_columns:\n",
    "    dataset_files_path[col] = dataset_files_path[col].fillna(dataset_files_path[col].mode()[0])\n",
    "\n",
    "# Нормализация числовых данных (мин-макс нормализация)\n",
    "dataset_files_path[numeric_columns] = (dataset_files_path[numeric_columns] - dataset_files_path[numeric_columns].min()) / (\n",
    "        dataset_files_path[numeric_columns].max() - dataset_files_path[numeric_columns].min()\n",
    ")\n",
    "\n",
    "# Кодирование категориальных данных\n",
    "data_encoded = pd.get_dummies(dataset_files_path, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Загрузка модели\n",
    "model_path = 'Air_Quality_Prediction.joblib'\n",
    "model = joblib.load(model_path)\n",
    "\n",
    "# Подготовка данных для модели\n",
    "expected_features = model.feature_names_in_\n",
    "missing_features = set(expected_features) - set(data_encoded.columns)\n",
    "\n",
    "# Добавляем отсутствующие признаки, заполняя их нулями\n",
    "for feature in missing_features:\n",
    "    data_encoded[feature] = 0\n",
    "\n",
    "# Оставляем только нужные признаки для модели\n",
    "data_final = data_encoded[list(expected_features)]\n",
    "\n",
    "# Применение модели для прогнозов\n",
    "predictions = model.predict(data_final)\n",
    "data_final['Predictions'] = predictions\n",
    "\n",
    "# Сохранение обработанных данных\n",
    "processed_file_path = 'processed_data_air_quality.csv'\n",
    "data_final.to_csv(processed_file_path, index=False)\n",
    "print(f\"Обработанные данные сохранены в {processed_file_path}\")\n",
    "\n",
    "# Сохранение прогнозов\n",
    "predictions_file_path = 'predictions_air_quality.csv'\n",
    "data_final.to_csv(predictions_file_path, index=False)\n",
    "print(f\"Прогнозы сохранены в {predictions_file_path}\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5vwuU-e_w5Uu",
    "outputId": "76c1e6c0-ab27-4267-9e60-2aff519fb2b2"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Обработанные данные сохранены в processed_data_air_quality.csv\n",
      "Прогнозы сохранены в predictions_air_quality.csv\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-13-5b05d44382f1>:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_final['Predictions'] = predictions\n"
     ]
    }
   ]
  }
 ]
}
